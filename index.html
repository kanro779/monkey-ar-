<!doctype html>
<html lang="ja">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"/>
  <title>Simple Face Overlay (WebAR)</title>
  <style>
    html,body{margin:0;height:100%;background:#000;}
    #wrap{position:relative;width:100%;height:100%;overflow:hidden;}
    video,canvas{position:absolute;inset:0;width:100%;height:100%;object-fit:cover;}
    #hint{position:absolute;left:0;right:0;bottom:10px;color:#fff;text-align:center;font:14px system-ui;text-shadow:0 1px 3px rgba(0,0,0,.8)}
    #err{position:absolute;left:0;right:0;top:0;color:#fff;background:#c33;padding:8px;font:13px system-ui;display:none;}
  </style>
  <script type="module">
    import {FaceLandmarker, FilesetResolver}
      from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.8";

    let video, canvas, ctx, fm, ready=false;

    // 1枚重ねるだけのPNG（このファイルと同じフォルダに置いてあります）
    const img = new Image();
    img.src = "./mask.png";

    // MediaPipeの主要ランドマーク番号
    const L = {EYE_OUT_L:33, EYE_OUT_R:263};

    async function init(){ 
      try {
        video  = document.getElementById("cam");
        canvas = document.getElementById("overlay");
        ctx    = canvas.getContext("2d");

        // カメラ（フロント）
        const stream = await navigator.mediaDevices.getUserMedia({
          video:{facingMode:"user", width:{ideal:1280}, height:{ideal:720}}, audio:false
        });
        video.srcObject = stream;
        await video.play();

        // MediaPipe 読み込み
        const resolver = await FilesetResolver.forVisionTasks(
          "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.8/wasm"
        );
        fm = await FaceLandmarker.createFromOptions(resolver, {
          baseOptions:{
            modelAssetPath:"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.8/wasm/face_landmarker.task"
          },
          numFaces:1, runningMode:"VIDEO"
        });

        const fit=()=>{canvas.width=video.videoWidth; canvas.height=video.videoHeight;};
        if (video.readyState>=2) fit(); else video.onloadedmetadata=fit;

        ready = true;
        requestAnimationFrame(loop);
      } catch(e) {
        const el = document.getElementById("err");
        el.style.display = "block";
        el.textContent = "カメラの起動に失敗しました。HTTPSでアクセスしてカメラ許可を与えてください。詳細: " + e;
      }
    }

    function p(n, w, h, arr){ return {x:arr[n].x*w, y:arr[n].y*h}; }
    function dist(a,b){ return Math.hypot(a.x-b.x, a.y-b.y); }

    // 見た目調整（必要ならここだけ編集）
    const FIT = {
  widthByEye: 3.8,   // ← 2.6から大きく。猿の顔が確実に見える
  aspect: 1.0,       // mask.pngは正方形だから1.0
  offsetY: 0.1,      // まずは少し上めに。0.28→0.1
  offsetX: 0.0
}

    async function loop(){
      if(!ready) return;
      const now = performance.now();
      const r = await fm.detectForVideo(video, now);
      ctx.clearRect(0,0,canvas.width,canvas.height);

      if(r.faceLandmarks?.length){
        const lm = r.faceLandmarks[0];
        const w = canvas.width, h = canvas.height;

        // 基準点：両目外端
        const le = p(L.EYE_OUT_L,w,h,lm);
        const re = p(L.EYE_OUT_R,w,h,lm);
        const cx = (le.x + re.x)/2;
        const cy = (le.y + re.y)/2;

        const eyeDist = dist(le,re);
        const angle = Math.atan2(re.y-le.y, re.x-le.x);

        // 画像サイズ・位置
        const maskW = eyeDist * FIT.widthByEye;
        const maskH = maskW * FIT.aspect;
        const offX  = FIT.offsetX * eyeDist;
        const offY  = FIT.offsetY * eyeDist;

        ctx.save();
        ctx.translate(cx + offX, cy + offY);
        ctx.rotate(angle);
        if (img.complete) {
          ctx.drawImage(img, -maskW/2, -maskH/2, maskW, maskH);
        }
        ctx.restore();
      }
      requestAnimationFrame(loop);
    }

    window.addEventListener("load", init);
  </script>
</head>
<body>
  <div id="wrap">
    <div id="err"></div>
    <video id="cam" autoplay playsinline muted></video>
    <canvas id="overlay"></canvas>
    <div id="hint">顔を中央に。カメラ許可をON。必要なら index.html 内の FIT を微調整。</div>
  </div>
</body>
</html>
